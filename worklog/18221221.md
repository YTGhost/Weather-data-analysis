# 工作日志

## Day1

在本机上安装spark等基本环境

本地安装三台Ubuntu虚拟机建立集群

协调组员分工

帮助组员学习Git

建立Github和华为云仓库

## Day2

在学校虚拟机上搭建spark集群环境

帮助组员学习Git

## Day3

修改集群的一些Bug，修改了集群结点内存限制

配置好了Anaconda环境

搭建Jupyter NotebookWeb环境，使我能在本地访问远程虚机的Notebook页面。并与pyspark连接，这一步遇到了一些问题，谷歌后解决。

学习pyspark的操作中。。。

## Day4

了解了spark各种模式的运行：单机local模式、独立的spark集群模式（Standalone模式）以及使用spark集群+Hadoop集群的模式（包括yarn-client和yarn-cluster模式）

学习了pyspark数据处理，包括基本的RDD转换和基本动作，分布式广播变量与累加器，持久化缓存，Spark SQL临时表，过滤等等。

再次修改了关于集群的三个Bug

### 1

Caused by: java.io.IOException: error=13, Permission denied

修改环境变量

![image-20200701231845536](http://image.hihia.top/Screenshot/20200702170718.png)

### 2

![image-20200702012526350](http://image.hihia.top/Screenshot/20200702170738.png)

需要上传文件到HDFS中

![image-20200702013551163](http://image.hihia.top/Screenshot/20200702170743.png)

### 3

![image-20200702080750351](http://image.hihia.top/Screenshot/20200702170828.png)

通过查看hadoop的nodemanage的工作日志，发现：

![image-20200702081610007](http://image.hihia.top/Screenshot/20200702170830.png)

即虚拟内存使用超标了，经查询，这个2.1是由yarn-site.xml中配置计算而来的，yarn.scheduler.minimum-allocation-mb * yarn.nodemanager.vmem-pmem-ratio = 虚拟内存的总量。

由于我在xml中两者都没配置，上述两值预设为1G和2.1G，超过了自然就被kill了

添加如下设置问题解决

![image-20200702083449819](http://image.hihia.top/Screenshot/20200702170833.png)

## Day5

接手了后端flask项目和前端Vue项目，整理完善，搭建在了服务器上。

![image-20200703175227124](http://image.hihia.top/Screenshot/20200703175229.png)

## Day6

筛选了全国的气象数据

修改了前端Vue项目的一些小bug

![](http://image.hihia.top/Screenshot/20200704172434.png)